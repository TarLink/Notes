Code quality:
  - auto-beautifier
  - escomplex

Short-term:
  - on next yargs release, remove "undefined" from opt.choices

GraphQL-anywhere:
  - should replace graphql-anywhere with own code
  - library:
     - does sometimes too much (e.g. selecting should be a different middleware, since REST will use args.select)
     - is not functional friendly
     - harder to debug
     - slow at solving issues.
  - do it by copy pasting it, convert to ES8, and remove unneeded parts
  - separate selecting into another middleware, with args.select being deduced from GraphQL query
  - must support null as inputObject (which is not currently supported), and undefined
     - make sure it works with "update" action
  - separate all GraphQL-related code to its own folder
  - operationName support
  - GraphQL introspection:
     - fix GraphQL __typename, it's wrong
     - support mixing GraphQL introspection query (e.g. __schema) with non-introspection query
  - look at GraphQL spec validation chapter, to make sure my validation layer conforms
  - GraphQL schema:
     - add __metadata, including pagination
     - arg.filter

Waterline ORM:
  - add a layer just before database action layer, where:
     - if actionType replace|upsert, replace arg.data.id by arg.filter { id } (for *One)
       or arg.data[*].id by arg.filter OBJ_ARR { id } (for *Many)
  - add Waterline ORM:
     - parse arg.filter as ORM object (see arg.filter normalization)
     - equality must be deep equality for ARR|OBJ, so people can do { filter: { attr: ARR|OBJ } }
  - remove the pSetTimeout(0) in databaseExecute middleware

arg.filter normalization:
  - small normalization done during normalization middleware:
     - does not change format, just add defaults, e.g. VAR: VAL becomes VAR: { eq: VAL }
     - also validate that arg.filter.id is defined and is the only one, when command readOne|deleteOne
  - format:
     - is to be determined??? Bur basically MongoDB/Waterline-like, client-friendly
     - is converted to actual Waterline object at the database layer
     - should include "or" (alternatives), e.g. with ARR
  - think is some dataValidation makes sense for args.filter, e.g. minimum|maximum or type

Authorization:
  - IDL functions for idl|model|attr.authorize:
     - FUNC[_ARR]: ARR is && (normalized during IDL transformation)
     - can use IDL functions variables|helpers
  - idl.authorize FUNC[_ARR]:
     - for all models, performed once per request, just before main operation middleware
     - i.e. less IDL functions variables, and no partial evaluation
     - if resolves to false, do not perform query and returns 403
  - model.authorize FUNC[_ARR]:
     - model-wise
     - if fails, returns 403 (except for find|delete commands which might augment arg.filter)
     - according to command:
        - find|delete: $/$$: augment arg.filter (see below)
        - create: $/$$: use arg.data
        - update: $/$$: use both arg.data and args.currentData (tried after another)
        - update|create: if command.multiple, check model.authorize for each arg.data and each args.currentData.
          If any fails, 403.
     - in authorization middleware, just before dataValidation middleware
     - find|delete commands use partial evaluation:
        - exception during partial evaluation should throw 5** not 4**
        - use resulting database query object, if there is one, by && it
           - if resolves to false, do not perform query and returns 403
        - must try partial evaluation during IDL validation to make sure it works runtime
        - do not pass $/$$ to non-inline functions, because cannot be partially evaluated
     - find commands of replace|upsert action should not be affected (using args.authorization false)
  - attr.authorize FUNC[_ARR]:
     - same as model.authorize, except:
        - can use $ (same as $$.ATTR)
        - action when not authorized differs. Depending on command:
           - read:
              - silently removed in output
              - only checked if defined in output (i.e. key is present)
              - on all commands
           - create|update|delete:
              - silently replace new value (arg.newData.ATTR) by current value (args.currentData.ATTR)
              - only checked if new value !== current value
              - in order: if current value is empty, use "create". If new value is empty, use "delete".
                Otherwise, use "update".
              - on update command only
  - model|attr.authorize.COMMANDS:
     - like authorize, but applied according to current command
     - authorize VAL is normalized (by IDL transformation) to authorize.create,read,update,delete VAL
     - COMMANDS can be read|update|create|delete. Can be comma-separated list.
        - command.multiple does not matter, i.e. no authorization mismatch possible on nested actions
     - replaces idl.commands and model.commands (which must be removed):
        - forbidden goals:
           - are goals whose authorize always return false for a
             given set of protocol/operation IDL functions variables + COMMAND param (e.g. without $/$$)
              - how to know? partial evaluation?
           - 403 becomes 405 on forbidden goals
           - forbidden goals not shown in GraphQL schema
        - add Allow [S] on every response:
           - does not show forbidden goals

Aggregating:
  - are just other actions, following similar logic as the others
     - should also think of which other actions it requires, and which one it implies
  - e.g. countUsers, groupUsers, etc.
  - arg.distinct "ATTR": no duplicates
  - is basically asking for server-side multi/single-ATTR/OBJ operations, so maybe try to allow client to specify
    it as JavaScript, parsed as MongoDB aggregate object???
  - think of interaction with pagination

Pagination:
  - keep the current situation that:
     - create|upsert|replace do not paginate, but arg.data length is limited by pageSize
     - delete|update paginate output only, not write query itself
        - but currentModels for update needs an unpaginated first find command then???
        - main reason is it is hard with nested queries???
     - find is paginated
  - agnostic to nesting, i.e. action-wise not operation-wise
  - metadata:
     - should not be selectable, i.e. always fully rendered in output
     - action-wise, not model-wise
     - in output, is sibling to "data", in both GraphQL and REST:
        - data.ACTION_PATH METADATA_OBJ
  - pagination metadata:
     - previous|next_token "CURSOR":
        - used with args.after|before "CURSOR"
        - "CURSOR" uses same as current system, including "" for beginning|end
        - those two cursors are simply the cursor calculated of the last and first model
        - undefined if no previous or no next page
        - cursors should store oArgs and use them for comparisons, not normalized args.
          Clients should submit the same args.filter|order_by (instead of not submitting any, as it is now), i.e. only add args.after|before.
     - first_token|last_token: always ""
     - has_previous|next_page BOOL, page NUM, page_size NUM, args.page_size NUM, args.page NUM: same as current system
  - Relay.js:
     - requires model-wise cursors, which is too slow, and too complicated for users, i.e.:
        - only expose Relay.js cursors as opt-in
        - only first and last cursor are calculated. The others simply append an offset to the first cursor.
          It is not as isolation-safe, but is much faster and only meant for Relay.js
  - replace runOpts maxPageSize, defaultPageSize and maxDataLength by only runOpt pageSize NUM:
     - defaulting to 1000
     - 0 to disable:
        - args.page_size and runOpts.pageSize 0 are like Infinity, i.e.:
           - if runOpts.pageSize 0, args.page_size can be anything
           - args.page_size can only be 0 if runOpts.pageSize 0
        - no pagination metadata response
     - used as default page_size, max page_size and max args.data size
  - pagination error messages on wrong cursors are not clear
  - use Range [C] and Accept-Ranges [S] for pagination
     - e.g. transforming them into pagination regular arguments
  - total_size and page_count???
  - first|last|previous|next:
     - like first|last|previous|next_token, but prepended with URL to perform the query
     - URL might have different action than current action, e.g. delete|update output is paginated, but pagination should
       use find, e.g. delete|update -> find
     - for GraphQL, need to put query in the URL query string
     - for nested models, is the URL that would be used if those models were not nested
     - also as HTTP Link: <URL>; rel="first|last|prev|next|self[ ...]"; action="findPets.findFriends":
        - should be single Link, not two, if have same URL

Compatibility layer:
  - reporting deprecation
  - breaking changes:
     - notify when schema change introduces breaking change (e.g. graphql.js provides that)
  - think about how to version IDL file
  - autoversioning:
     - might be related to breaking changes feature
  - migrations helpers
     - when changing IDL constraints, should migrate data so they conform to new constraints
     - when adding default|transform, should migrate data, otherwise when doing update with empty data,
       or find followed by replace, both should be idempotent, but default|transform would actually be applied
  - should it generate redirects when name has changed?
  - feature flags

Versioning/changes:
  - can probably link together versioning, changes and undelete features
  - versioning:
     - on any model modification
     - should allow restoring
        - including undeleting:
           - use query parameter "show_deleted" and model attribute "deleted"
     - should allow searching
     - maybe, instead of introducing new goals/actions, use special attributes to search or update
  - listening for changes:
     - should emit change events, but not know how they are used, i.e. not know the subscriber side
        - alternative is to emit events on ApiServer eventemitter for local consumption.
          Less decoupling, but easier to implement and consume.
          Might even be able to do both, e.g. add a module that translate local events into remote events.
     - should allow listeners to catch up if they missed some events because of network problems
     - should allow listeners to target specific: model, attribute, value, condition on value (e.g. value < 5),
       request context, request user, etc.
       Does not mean emitter perform those checks, but that it allows them to be performed
     - make it easy to integrate with SaaS integrations, e.g. "use this service to send an email"
  - separate from rest:
     - done after the request was handed back to client, i.e. no impact on performance
     - done in different database
        - could be single table with streams of changes
  - can problably use standard diff format, e.g. JSON patch or JSON merge patch.
    Could also store models in full
  - can limit max number of versioned models by time or by absolute number or a combination
     - need to make sure change listeners can still get all events without model being removed from their reach
  - maybe use HTTP memento
  - maybe use semantic links, e.g. Link: <URI>; rel="alternate|canonical|latest-version|working-copy|predecessor-version|
    successor-version|version-history" [S]
  - must version IDL file format itself, and also apiEngine itself

Exception handling:
  - error reasons:
     - rationalize|reduce error reasons:
        - should be not about guessing where error was internally triggered, but in terms of how client should respond.
        - e.g. it does not matter if InputValidation error is because args.data is wrong or args.filter, what matters is that
          client displays that input is wrong.
  - should add `extra` information to any throw ERROR that possess interesting information.
     - all errors with the same `reason` should expose the same `extra` variables
  - document available error responses types, error `extra` and status codes
  - add all `generic.title`

Error reporting:
  - improve error messages for JSON schema composed types: schema.contains|propertyNames|not|anyOf|oneOf|if|then|else (others are fine)
  - error response should include parsable info for validation errors:
     - data that failed
     - data path: either as JSON path (def) or as JSON pointer (using a runOpt)
     - rule (e.g. 'exclusiveMinimum')
     - operation context (e.g. action, fullAction)
     - any other relevant info
  - add `locations` attribute to GraphQL errors, and possibly other documented in my GraphQL doc
  - autocorrection|suggestions:
     - e.g. wrong|mispelled action|attribute name. Should be operation-independent
  - variants: if data validation fails because of an attribute that was generated as a variant, error message must include information that it was generated as such, otherwise it's confusing for end-user
  - request timeout error includes very little information (e.g. does not include protocol) because it is fired in
    an early middleware

Data validation:
  - $data notation is a bit cryptic and prone to error with JSON pointers.
     - should replace to something more user-friendly, where user just need to specify the sibling model's attribute name
     - at the moment, $data is removed before IDL validation, this would need to be changed
     - validateMap would need to convert this notation to $data, for ajv to work
     - error reporting does not currently work with $data, because ajv does not translate $data into the actual referred
       data. E.g. it says "should equal [Object object]" because { $data: STR } is kept as is

inputValidation middleware:
  - like dataValidation middleware but before any server-side data transformation:
     - i.e. beginning of command layer
     - reuse attr.validation like dataValidation middleware
        - reason we do not have two different sets of validation: data stored in database should be valid input, and also having two sets adds two much complexity and room for errors to end-users
     - gives 4** client-side errors, while dataValidation middleware gives 5** server-side errors
     - input only (like dataValidation middleware)
     - should try to memoize|reuse per request (to avoid memory leaks) between inputValidation and dataValidation middlewars

Nested models:
  - rethink nested models: need to think about which value gets overriden when copying refered model,
    which value does not get overriden, and which value cannot get copied (e.g. description)
  - nested arrays+objects in IDL definition do not really work
  - what happens when a recursive action is applied twice to same model?
     - E.g. top-level action update model.attr to 1, but nested action update same model.attr to 2, i.e. the return value
       will show two copies of model, but with different value for attr, which is confusing and inconsistent.
     - also problematic for deletions.
     - this can also happen when the nested action of a Many action is the same accross invocations,
       e.g. deletePets() { deleteBestFriend() } where all pets have same bestFriend
  - nested create|replace|upsert:
     - if createPet's data.best_friend is missing and (nested) createBestFriend() is specified in query:
        - fill data.best_friend with dummy values, e.g. "", 0 (depending on type), single or array
        - do not pass any data.id in createBestFriend()
        - after createBestFriend(), update parent.best_friend using the response
           - that update should not be affected by def.actions restrictions
        - parent.best_friend resolver should wait for parent.createBestFriend resolver to end, and use its value

No orphans:
  - allow no orphans, considering that:
     - model relations can be:
        - optional|required for each part:
           - first part:
              - required means that second part => first part
              - not that first model's property is required
           - second part: inverse
        - single|multiple for each part
     - model relations can be changed by:
        - adding for each part:
           - adding first part, which might happen during create|update|replace|upsert
           - adding second part, which happens during create
           - should make whole action fail if any part would become orphan (according to requiredness)
        - removing for each part:
           - removing first part, which might happen during delete|update|replace|upsert
           - removing second part, which happens during delete
           - should trigger cascade removal when any part would become orphan (according to requiredness)

Data correctness:
  - code makes assumptions about database correctness:
     - e.g. that created_time is defined
     - should list those assumptions
     - should have a way to check and report database incorrectness

ACID:
  - Atomicity:
     - if any supermodel|submodel fails, make whole action fail, and revert previous changes
  - Isolation:
     - when writing on several models, do a snapshot so that the return value is consistent. Not sure if worth.
     - problem on multi-queries actions:
        - update -> A finds model, then updates it, but B deleted it in-between
        - upsert -> A finds model, then updates it, but B deleted it in-between.
          Or A does not find model, then creates it, but B created it in-between
  - Durabillity

Schema strictness/polymorphism:
  - think about additional properties (not specified in schema), and whether to allow them in input, and in output:
     - at the moment, they are allowed
     - if want looser schema, think of impact on:
        - validation: see related JSON schema keywords: prohibited, additionalProperties, patternProperties, patternRequired,
          propertyNames, additionalItems
        - GraphQL schema
  - should it be allowed to specify an unknown ATTR in order_by, reduce, etc.?
  - allow mixed arrays:
     - i.e. using schema.items SCHEMA_ARR instead of schema.items SCHEMA
     - also schema.additionalItems
     - re-verify error messages for those two properties
  - overloading, i.e. union types:
     - in GraphQL, use "union" maybe.
     - could be done by passing array of schema.type or schema.model
        - there is already some basic support for schema.type array in IDL validation
  - subtyping:
     - both nominal (e.g. guessing type using an attribute as differentiator)
     - or structural (e.g. guessing type from which attributes are there, or which are their types)
     - in GraphQL, use "interface" maybe
     - add the moment GraphQL fragment "on TYPE" are noop, i.e. always return true whatever TYPE is

Async actions/tasks:
  - task management (restarting, retrieval, etc.)
  - Async actions must be well thought as they slow down requests:
     - there should be jobs reported to users and users should be able to control max wait time.
     - when this is figured out, think of how async IDL functions would work within that
        - consider that paramsRef is directly mutated, i.e. might not be thread-safe
     - try to think if need generic async actions output (e.g. HTTP 202, Prefer: respond-async [C], Prefer: wait=NUM [C])
  - see REST doc for more info

Upsert command:
  - at the moment there's a fifth command "upsert":
     - the reason is to avoid launching two separate commands "create" and "update":
        - for perf reason
        - and because database sorting, paginating, etc. would need to be done at API-level (merging the two commands)
     - problem:
        - having simply the 4 CRUD commands would be simpler
        - authorization uses the 4 CRUD commands, i.e. is in mismatch
        - author|timestamps plugins require to know if a "create" or "update" command will be performed,
          i.e. $COMMAND idlFunc variable need to be among 4 CRUD commands only
     - possible solution:
        - having a model-wise command, instead of action-wise
        - since upsert does a first read command, it is possible to know if each model is a "create" or "update"

API base types:
  - attributes that are objects (or array of objects) but not models:
     - at the moment, are not allowed, because we want the user to take advantage of using models: creates endpoint,
       documentation, etc.
     - think whether this is a good idea?
     - this means JSON schema object validation will never be used (although technically allowed)
  - enum type:
     - with possibility to add metadata (description, deprecation, etc.) on each value
     - think if needs to allow transform between database representation and API representation
     - might use schema.constant|enum in JSON schema
     - might use GraphQL enum
  - new types beyond JSON ones:
     - must still be serializable|parsable from JSON
     - must be of the correct type when in API layer
     - must work with arg.filter normalization
     - must work with pagination cursor serialization
     - might want special GraphQL types for proper schema, e.g. special GraphQL scalar types
     - validation layer must handle them correctly
     - e.g. undefined, function, Infinity|NaN
     - allow custom types

Model.id:
  - must ensure cannot change model.id
  - allow configuring name and type of `id` attribute, including with findOne(), etc. actions that use that argument.
     - should probably whitelist possible types, e.g. probably only string or number make sense
  - allow alternate ids, e.g. a query can either use machine-friendly `id` attribute, or human-friendly `name` attribute

Static file serving:
  - take inspiration from existing ones, probably reusing one
  - take inspiration from Express sendFile()
  - think of Content-Disposition
  - integrate GraphiQL with this
  - server-side templates serving
     - including isomorphic server-side renderer

Server routing:
  - compare with existing libraries, and see if should reuse one and/or their features

Realtime:
  - protocol-agnostic, i.e. WebSocket protocol is just one option
  - subscriptions (on-demand or automatic after a query|mutation)
  - maybe something like:
     - create an endpoint to setup connection, where specify if want automatic or on-demand
     - if on-demand, must then pass extra parameter to operations (via params) or actions (via arguments)
       to specify want to subscribe

Concurrency conflicts:
  - locking or MVCC (automatic merge conflicts)
  - preconditions, including HTTP (e.g. If-Match [C])
  - errors, including HTTP 409
  - see concurrency chapter in to_learn.txt
  - problem with concept of "changed" in variants middleware:
      - e.g. if clientA fetches model as { a: 1 } then clientB saves it as { a: 2 }, then clientA saves it as { a: 2 } as well,
        "a" will not be considered "changed", although it should, because "changed" is not about which attributes changed from
        a server perspective, but about which attributes a client tried to change, i.e. from a client perspective.
      - e.g. variants middleware won't work properly, e.g. clientA fetches model as { oldA: 1, newA: 1 }, then clientB
        saves it as { oldA: 2, newA: 2 }, then clientA saves it as { oldA: 1, newA: 2 }.
        clientA intents here to chamge variant using "newA", but "oldA" will be used instead

Protocols:
  - HTTP server events "checkContinue" (for 100-continue [C]), "connect" (for CONNECT), "upgrade" (for Upgrade [C])
  - HTTP/2
  - make sure it works well with proxies

HTTP details:
  - Add support for 204 status code, with any write goal

HEAD:
  - add support for HEAD method, different from noOutput settings:
     - Content-Length should not be 0.
     - it should be at protocol level, just sending the same response headers but no content

Direct database access:
  - how to handle when modification is done directly on the database, not through the API layer?
     - example when this might create problems: no versioning done, no validation done, no transformation done, etc.
     - should direct access to database be readonly? Should there be a Cron task fixing data instead?

Database constraints:
  - uniqueness
  - indexes
  - non-null

Model naming:
  - idl.models.MODEL.names STR_ARR:
     - instead of MODEL.model
     - while MODEL is how model is refered to in IDL, and is stored in database, this is about how model is communicated to client (e.g. GraphQL action names or REST URLs)
        - attr.type must refer to MODEL, not MODEL.model, to avoid name conflicts with JSON type,
          i.e. so that models can be called "string", "array", etc.
     - def to ["MODEL"]
     - must be IDL validated
     - if ARR.length > 1, extra ones are aliases
        - when an alias was used, should communicate canonical name (i.e. ARR[0]) to client using header: X-Api-Engine-Model-Name: MODEL [S] (protocol-agnostic) and Content-Location: MODEL [S] (HTTP-specific)

Database transformation layer:
  - before database action middleware
  - e.g. one model in two tables, two models in one table, database-specific info, for both input|output
  - should allow single server to use multiple databases with different technologies (e.g. MongoDB + Redis) too
  - possibility: using variants.ATTR.ATTR2 (instead of variants.ATTR) with ATTR being a nested model
     - in that case, need to think about consequences on $$ IDL function variable

Rate limiting:
  - should be shared between server instances
  - maybe at API gateway-level
  - see HTTP doc for standard headers and status codes

Security:
  - TLS
  - CORS
  - XSS
  - CSRF
  - general utilities, like "helmet"
  - should be protocol-agnostic as much as possible

Custom actions:
  - must be declared in IDL file
  - are global, not model-wise? if model-wise, nesting?
  - think of nested actions
  - middleware at beginning of action layer
  - must contain:
     - handler function:
        - can call core actions with normal args
        - get input from operation layer
     - information to build its GraphQL schema, and do input|output validation

IDL functions:
  - think if should use them in other parts of IDL
  - Add variables related to device|browser detection
     - add them to logging requestInfo too
  - think of we can simplify idl.helpers IDL syntax
  - make IDL variables immutable but:
     - not the helpers, cause they are external and might mutate
     - only once per IDL variable per request, because setting immutability is slow

Compile-time validation:
  - should IDL validate that validate.required|dependencies are only used at top-level:
     - because of JSON schema recursion, it's actually currently possible to do validate.allOf.required
     - this will crash, because we manipulate those properties at top-level, before calling ajv
  - according to each attr.type:
     - should validate that attr.validate only contain keywords for that type
     - attr.default is of that type
     - careful because attr.type is only decided after normalization
  - IDL functions:
     - validates when can that take either IDL function or a constant of the same type as the attribute,
       e.g. in attribute.default|transform
     - make sure IDL functions does not use unknown params, which is challenging because:
        - function body might not be readable, e.g. if function is bound
     - perform static analysis, e.g. linting
     - maybe validate complexity, e.g. max length

Custom code:
  - separating code into several packages
  - using a more plugin-oriented architecture:
     - allow users to write support for new protocols, operations, etc.
     - allow users to add|remove middleware
     - should do this with a decorated FUNC(APIENGINE)->APIENGINE, as opposed to using a run option
        - decorated APIENGINE should keep all features, including CLI

Callbacks/events:
  - not sure if this is a good idea
  - on new|finished layers
  - while events are async, callbacks are sync and allow modification of input/output

Caching:
  - protocol-level caching, including HTTP caching
     - allow specifying with protocol-agnostic settings, but also accept|produce standard HTTP caching
       (see Express.js for example)
  - automatic request caching, and invalidation:
     - between API and database
     - between client library and API
     - between client and client library, e.g. creating a client library that gets push from server on invalidation,
       so it does not even perform any request
     - saved on key-value store, so can be shared between instances
  - delta encoding

Optimization:
  - *Many actions should not spawn one sub-action per result:
     - e.g. if findModels return 5 models, at the moment, there will be 5 individual findSubModel,
       but they could be regrouped.
     - ideally, they should span only one action per sub-action, no matter the size of the returned array
        - this would imply that one action requested by client === single one action fired by server, even deeply nested
        - i.e. nesting has linear impact on performance
        - this also will make performance logging clearer, i.e. less items and less concurrent runs
     - do this operation-independant.
     - do this action-wise
     - see facebook data-loader for inspiration
     - possible implementation:
        - middleware just after executeGraphQL (or executeREST), i.e. operation-independant
        - middleware waits for next macrotask (setTimeout(..., 0))
        - on next macrotask:
           - see if other instance of that middleware are waiting too, for the same request and the same fullAction path
           - if so, run all of them as a single action
        - this would mean runs of that middleware would need to share a shared state (per request) to communicate with each
          other:
           - the middleware that trigger single action could communicate the promise of that action to the others.
             The others would not trigger anything, just wait for that promise to end, then pick the result they need.
  - size of array returned by *Many actions should not impact too much response time:
     - e.g. at the moment many things (e.g. attr.transform) is run once per model, where it could instead be run once for
       all models
  - look for memory leaks
     - check for memory leaks in memoize(), i.e. new requests should not increase memoize() memory retention
  - do performance profiling to see which parts are slow
  - memoize IDL functions run per request. Instead of stringifying ifv, use === comparison
  - concatenate IDL functions together:
     - e.g. `test` in transform/compute can be { test TEST, value VALUE } ->{ value (TEST ? VALUE : $) }
     - e.g. array of transform/compute can be concatenated into a single IDL function
     - apply IDL functions in batch, i.e. instead of applying same transform to several models of same collection, transform
       IDL function to $.map(FUNC) and apply on collection instead

Streaming:
  - input|output streaming:
     - protocol-level, e.g. HTTP
     - format-level, e.g. ndjson or YAML streams
  - Expect: 100-continue [C]

Testing:
  - unit tests:
     - test coverage
     - data-driven tests
     - fuzz testing
  - integrated tests
  - load testing
  - performance testing
  - greenkeeper

CI/CD

Logging/monitoring:
  - logging:
     - dashboard
     - go through docs and to_learn
  - monitoring:
     - host metrics
     - alerting
     - status page
  - distributed request tracing
  - analytics:
     - tell which models are used, which attributes, which versions, which params, etc.
     - might be able to build on logging feature ("call" type) for that

Dependencies:
  - package.json linting
  - learn more about npm, yarn, etc.
  - deprecation/security automatic check
  - changelog for the engine project itself
  - dependencies upgrades: choose strategy and tools (like greenkeeper)
  - deprecation for the features of the engine project itself

Refactoring:
  - performance monitoring is very verbose in the code on startup and exit
  - use ES6 import/export, when supported natively by Node.js
     - fix ESLint rules for that
     - no need for 'use strict' anymore nor ESLint impliedStrict true
     - use shrimpit

Nodemon exit in production mode:
  - when server.keepAliveTimeout is left to its default value (i.e. 5000), and Nodemon is running, and a request
    has just been fired (i.e. socket is still alive because of timeout), hitting CTRL-C will fail at freeing the
    socket, i.e. restarting right after will fail.
  - a former solution I had was to fire process.kill(process.pid, 'SIGUSR2') on shutdown event, but this was problematic:
     - if several servers are run at once (with or without Nodemon), this will make the first one that finished exiting
       abrupt the others
     - it adds Nodemon-specific code

Live database:
  - DaaS
  - backups
  - high-evailability
  - scalability

DevOps:
  - PaaS/FaaS
  - serverless:
     - since AWS lambda does not reuse Node REQ|RES, possible solutions:
        - treat AWS lambda as a different protocol, alongside HTTP
           - problem: there might be code duplication for the HTTP-related code, e.g. query string parsing
        - create utility that converts AWS lambda input to REQ/RES
  - easy to spawn multiple environments (stage, A/B testing, etc.)
  - Docker container
  - canary
  - rolling releases

System routing:
  - maybe as API gateway
  - load balancing
  - autoscaling

Authentication

Client:
  - Make some parts isomorphic, e.g. data validation, IDL file loading, IDL validation, etc.
  - Integration with frontend frameworks, client auto-generation

GraphQL relay:
  - must add clientMutationId, see https://facebook.github.io/relay/graphql/mutations.htm
  - must follow https://facebook.github.io/relay/graphql/objectidentification.htm

CLI tool:
  - for doing both administration, IDL edition, or custom functions

Admin dashboard:
  - like Mr.Wolf, but automated
  - for content management, basically a GUI to the API

REST:
  - including:
     - selecting
     - populating
     - right status codes, e.g. 201 + Location [S]
     - Accept-Patch [S]
     - being able to do several top-level actions like in GraphQL:
        query { a: findUsers(...), b: findUsers(...) }
     - return value aliasing, like in GraphQL
     - different envelope, i.e.:
        - REST:
            data
              ...modelData
              findSubModel
                data: subModelData
                metadata: subModelMetadata
            metadata: modelMetadata
        - GraphQL:
            data:
              findModel
                ...modelData
                findSubModel
                  ...subModelData
                  __metadata: subModelMetadata
                __metadata: modelMetadata

Other operations:
  - JSON-RPC
  - others

Debugging:
  - use GraphQL voyager instead of GraphiQL
  - graphiql should be according to Accept [C] (not route) with potential override
    with query variable like 'raw' to see raw result
  - HTML interactive output format when requesting from a browser

API documentation:
  - description:
     - build it using not only schema.description, but also schema.examples, schema.title and schema.* related to validation.
     - should be done during IDL compile-time transformation
  - printSchema():
     - better sorting
     - maybe change endpoint or way to get there.
     - improve syntax highlighting.
     - also maybe offer option to show full version, and offer simplified version by default,
       e.g. showing only one action, and not showing variants (nested, singular|plural, etc.)
  - API auto-documentation:
     - see REST doc for idea of everything that can be documented
     - provide API console for experimentation
     - code examples
  - changelog generation
  - add error_uri URL in error messages, pointing to documentation
  - parse comments in IDL file to include them in documentation and changelog.
    E.g. good to describe business-specific IDL functions.

Thorough dev documentation:
  - use jsdoc, esdoc or similar
     - see ESLint rules
  - API engine documentation website

Fake server:
  - fake data generation (using IDL to guess type/constraints), including mixed with real data
  - easy mock server generation for client, by using IDL file

Meta-information:
  - schema retrieval:
     - through API, e.g. /MODEL/schema
     - validation:
        - model's validation JSON schema:
           - Content-Type: application/schema+json [S]
           - can be directly usable with a library like AJV
        - model's IDL schema:
           - should also be linked to by each response as Link: <URI>; rel="describedby" [S]
  - semantic web
  - HATEOAS:
     - see REST documentation for ideas
  - general API "home document":
     - could use OPTIONS with HTTP as well

Output format:
  - offer other formats as data input|output: YAML, CSV, protobuf, XML, etc.
  - content negotiation:
     - allow specifying with protocol-agnostic settings, but also accept standard HTTP content negotiation
       (see Express.js for example)
     - types: format, encoding, language, charset
  - HTTP Content-Disposition
  - option to prettify output:
     - agnostic to output format.
     - should be as featureful as my JSON viewer Chrome extension: highligting, lines folding|collapsing, auto-URL-linker,
       toggle button to show raw, data available in console
     - automatically on when requesting from a browser.

Node.js version:
  - allow using other Node.js version than the latest

Other programming languages:
  - specified by using top-level property "language" in IDL file
  - allow other programming languages in IDL functions
  - allow other programming languages in functions imported by $ref
  - each new programming language must reimplement common functions like underscore.string
  - make sure JavaScript-specific logic does not apply to other languages

IDL format:
  - IDL file and runOpts file format:
     - allow other formats according to file extension: JavaScript, TOML, HJSON, etc.
     - should also add related custom parsers to $ref utility (json-schema-ref-parser) to handle those types
  - convert Swagger|RAML|API blueprint conf files into IDL format
     - allows those conf files as input, converting them first
  - yamllint the IDL meta-schema
  - create proper IDL file linter, inspired by ESLint
     - standard output (both as a string and as OBJ_ARR)
     - error locations
     - errors documentation URLS
     - autocorrections

Server-client state:
  - e.g. cookies, session, etc.
  - try to avoid having this feature unless necessary

Offline-first

i18n

Privacy feature

Central BaaS API:
  - deploying backends using IDL
  - IDL file's user management (who can modify IDL)
  - must submit not only IDL but also directory/project around it:
     - because compiled IDL still references files, including node modules
     - problem is size of hosting those directories
     - maybe should require GitHub repos, so no need to host

Sysadmin client app:
  - IDL edition:
     - should perform client-side:
        - basic format validation, e.g. YAML linting following by YAML parsing
        - IDL validation
        - IDL test compilation
        - all this should reuse isomorphic server code
  - GUI to central BaaS API

Promotion:
  - commercial website
  - ads:
     - X-Powered-By [S]

IDL migrations:
  - guessing an IDL from existing database.

Positioning:
  - main keywords: BaaS, featureful, easy, generic, stable, open-source
  - market: BaaS
  - main value: backend that is both featureful and easy to maintain
  - target audience:
     - developers, not newbyes
     - no assumptions on particular technologies or business cases
  - main requirements, in order:
     - featureful:
        - any feature a backend can provide
        - high quality design/implementation of each feature
     - easy:
        - maintainability: maintaining, setting up, upgrading, integrating, extending
        - manageability: operating, deploying, scaling, monitoring
        - learnability: documentation, support
        - UI dashboard: good UX, design, usability
     - generic/agnostic:
        - prefer generic over specific, even it lowers efficiency or performance:
           - i.e. interoperability with specific tools (client libraries, databases, etc.) is not paramount
             although nice to have
        - flexibility:
           - allow customizing business logic, with least assumptions about it
           - do not allow end-users customizing API design:
              - prefer forcing good API design over flexibility
              - but encourage contributors to customize API design through generic plugin architecture
     - stable:
        - tested, secure, reliable, available, recoverable
  - configuration:
     - featureful, i.e. many configuration options, which is ok
     - but easiness achieved thanks to:
        - minimal API surface for each option, by sacrificing specificity/efficiency over genericity
        - each option should have good default so they rarely need to be used
   - open source

4 months to finish features
1 month for quality
1 month for infrastructure

 2 CLEANUP
 1   Compile-time step
 1   GraphQL-anywhere

 30  MUST HAVE FEATURES
 3   Waterline ORM
 4   arg.filter normalization
 3   Authorization
 5   Aggregating
 2   Pagination
?7   Compatibility layer
?7   Versioning/changes
 1   Exception handling
 0.5 Data validation
 1   Error reporting
 1   inputValidation

 20  DATA MODEL
?2   Nested models
?1   No orphans
?0.5 Data correctness
?3   ACID
?7   Schema strictness/polymorphism
?0.5 Upsert command
?3   API base types
 1   Model.id

 15  NICE TO HAVE FEATURES
?3   Async actions/tasks
 2   Static file serving
 1   Server routing
?4   Realtime
?2   Concurrency conflicts
 1   Rate limiting
 3   Security

 10  NOT ESSENTIAL FEATURES
 1   Protocols
 0.5 HTTP details
 0.5 HEAD
?1   Direct database access
?0.5 Database constraints
 1   Model naming
?3   Database transformation layer
?2   Custom actions
 1   IDL functions
 1   Compile-time validation
?3   Custom code
?1   Callbacks/events

 40  SOFTWARE QUALITY
?6   Caching
?7   Optimization
 1   Streaming
 15  Testing
 2   CI/CD
 6   Logging/monitoring
 2   Dependencies
 2   Refactoring
 0.1 Nodemon exit

 70  DEVOPS/LIVE
 2   Live database
?10  DevOps
?2   System routing
?20  Authentication
?10  Client
 2   GraphQL relay
?5   CLI tool
?25  Admin dashboard

 50  DEV FEATURES
 7   REST
 5   Other operations
 3   Debugging
 10  API documentation
 20  Thorough dev documentation
?2   Fake server
?3   Meta-information

 20  NOT IMPORTANT FEATURES
 4   Output format
 3   Node.js version
 10  Other programming languages
?    IDL format
?    Server-client state

?    Offline-first
?    i18n
?    Privacy feature
?    Central BaaS API
?    Sysadmin client app
?    Promotion
?    IDL migrations
?    Positioning
