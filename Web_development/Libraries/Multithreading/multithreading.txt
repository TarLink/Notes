
                    
   MULTITHREADING   
                    



Multiprocessing: several CPUs on one machine
Multiprogramming: several processes on one CPU
  - multitasking: several tasks on one CPU (i.e. switch between tasks not processes)
Multithreading: several threads on one process
  - simultaneous: at the same time
     - hyperthreading: marketing term by Intel for it
  - temporal: alternated with a "thread switch"

Process: n threads + 1 shared address space
Thread: 
  - has own thread-local storage (TLS)
  - according to privileges, can be kernel or user thread
     - kernel thread can switch address space
Task: process or thread

Process Control Block (PCB) or switchframe: current tasks and process state, kept by OS

Task scheduling:
  - handling tasks state (running, idle, blocked, to be removed)
  - task switch: 
     - when state changes
     - cancellation point: when task switch can occur
     - can be:
        - sync (triggered by current instruction) or async (triggered by external event)
        - precise (interrupts at stable cancellable point and goes back to it) or imprecise
     - types:
        - sync:
           - precise, e.g.: sleep, yield, lock release
           - imprecise (exceptions):
              - e.g. software interrupt, i.e. CPU exception (e.g. runtime error)
        - async:
           - using hardware interrupt / interrupt request (IRQ):
              - e.g. devices
                 - including input, network
                 - including IRQ0, i.e. clock timer
              - trigger interrupt handler / interrupt service routine (ISR)
              - masking:
                 - prevent handlers from being fired
                 - non-maskable interrupts (NMI) do not allow it
              - rate limiting often used to prevent handlers from taking whole resources ("interrupt storm")
           - OS allowing IRQ are "preemptible" (as opposed to "cooperative"):
              - they usually allow max "time slice" for a given task before task switch

Paradigm:
  - acquiring resource:
     - spinning / busy waiting / software-driven: 
        - using spinlocks:
           - test if resource locked repeatedly, unless not locked
           - polling|sleeplock: when there is a fixed sleep time
     - event-driven / interrupt-driven: 
        - test if resource locked using interrupts
        - condition variable:
           - application-level alternative to interrupts
           - task subscribe to a conditional variable, in order to own resource
           - other tasks notify change of condition to conditional variable, in order to potentially release resource
  - releasing resource:
     - sync|blocking: do not yield
     - async|non-blocking: yields, then communicate end by using interrupts
  - difference:
     - spinning / sync: easier to code (more geared towards structured programming)
     - event-driven / async: performance

Priority inversion:
  - A (high priority) waits for C (low priority) resource, B (middle priority) waits for nothing
  - i.e. B prevents C from running, which prevents A from running, even though A has more priority than B
  - can solve with priority inheritance: making C temporarily high priority because it is required by A

Resource:
  - anything that can be used by competing tasks
  - e.g.:
     - processing: e.g. CPU. Handled by OS timesharing
     - memory: e.g. file, socket, variable
  - ownership (i.e. usage):
     - exclusive vs shared
     - write vs read

Critical section:
  - code section assuming exclusive ownership over a given resource
  - collision: when two tasks critical sections happen at same time
     - i.e. assume exclusive ownership but do not have it
     - race condition: when collision is time-dependent (i.e. non-deterministic)
     - solution: process|data synchronization
     - "thread-safety": avoid collisions
  - critical sections should be minimized|avoided as they require synchronization, which reduces parallelism|multithreading

Process synchronization:
  - avoid collision during critical section by making context switches (interrupts, exceptions):
     - impossible (atomic operations):
        - e.g. single CPU instruction
        - buffering prevent atomicity, since it delays operation
        - "read-modify-write" operation:
           - atomic operation doing several instructions
           - e.g.:
              - compare-and-swap (CAS): if X == Y { X = Z }
              - test-and-set: X2 = X; X = Y; return X
              - fetch-and-add: X += Y
     - not harmful (exception-safety):
        - code section that cannot trigger collisions nor memory leak even if exceptions are thrown
        - RAII:
           - pattern when creating|destroying resource also locks|unlocks it
           - i.e. make it exception-safe providing object is automatically destroyed when exception is thrown

Data synchronization:
  - avoid collision during critical section by preventing resource ownership
  - e.g.:
     - mutex:
        - flag:
           - checked and set when owning resource 
           - unset when released, by same tasks having set it
        - types:
           - unique: 1 task owns write+read
           - shared: 1+ tasks own read, prevent write
           - recursive: can set flag several times, i.e. it must unset several times
           - timed: unset flag after timeout
     - semaphore:
        - like recursive mutex, except flag can be unset by other tasks that ones that set it 
     - barrier|rendezvous:
        - like semaphore, except action is delayed until resource locked
  - locking:
     - implies blocking other tasks, which results in either:
        - waiting:
           - starvation: when endless
           - deadlock: mutual starvation, i.e. several tasks need the others' resources and cannot release their own until others acquired
           - livelock: deadlock where there is a function trying to solve it, but it always end up in a new deadlock
        - giving up
     - can imply resource leak if resource not unlocked after use
        - e.g.: memory leak, handle leak

Reentrancy:
  - can be paused by interrupts without problems
  - implies:
     - does not use global variables
     - does not use 

Pour être reentrant :
  - ne pas accéder de variables global non-const
  - ne pas appeler soi-même de fonctions non-reentrantes.
  - ne pas modifier son propre code (self-modifying code)

Volatile variables : cf c_synthese et c++_synthese pour l'utilisation de volatile sur les variables partagées par plusieurs threads

Puisque bloquer et libérer une ressource provoque un changement de contexte (avec une prise en charge particulière de l'OS pour cet événement), cela peut être utilisé pour les signaux :
  - le thread 1 bloque SIGFOOBAR_Mutex, partagé avec le thread 2
  - quand le thread 2 veut envoyer le signal SIGFOOBAR au thread 1, il débloque SIGFOOBAR_Mutex
  - l'OS prend en charge le signal

resource tracking : recherche par un OS ou une VM, d'un resource leak. Exemple : garbage collection

Join : fait qu'un thread attend qu'un autre arrive à un certain endroit pour continuer sa propre exécution.

Monitor :
  - classe dont toutes les méthodes sont gérées via des mutexs, thread-safe donc

Une cancellation ne peut avoir lieu que lors d'un cancellation point.
Cancellation handler : handler utilisé si la ressource cesse d'être utilisée par le thread actuel (par exemple, libérer la mémoire) Utile pour les asynchronously et synchronously cancelable threads.
Cancellation status d'un thread :
  - asynchronously cancelable : peut être cancelled à tout moment (défaut).
  - synchronously cancelable : ne peut être cancelled que lors d'un cancellation point.
  - uncancelable : ne peut pas être cancelled (une des manière d'implémenter une critical section).
