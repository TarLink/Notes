
                 
   SEO_GENERAL   
                 


  - have single URL (see above)
  - cloaking:
      - showing different content according to environment, e.g. user-agent
      - can be considered an attempt to trick search engines, unless Vary [S] is used


																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:          VOCABULARY           :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


SERP ==>                                        #Search Engine Results Page


																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:       CRAWLING/INDEXING       :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


CRAWLING/INDEXING ==>                           #Crawling: 
                                                #  - search bot fetches and stores page
                                                #  - should never need to disallow
                                                #Indexing: 
                                                #  - search engine uses either crawled page or "linked to" page to show search results
                                                #  - should only disallow:
                                                #     - when URL or response is confidential (e.g. URL confidential token)
                                                #     - but not when response confidentiality is protected by authorization (e.g. 401)

SEARCH BOTS USER AGENTS ==>                     #Googlebot

ORIGIN/robots.txt                               #INI format for crawling:
                                                #  User-agent: USERAGENT
                                                #  [Dis]Allow: DIR
                                                #  ...
                                                #Globbing|regexp:
                                                #  - * ? $
                                                #  - only * in User-agent

SITEMAP ==>                                     #Declared in robots.txt:
                                                #  Sitemap: URL
                                                #Is a XML file:
                                                #  <?xml version="1.0" encoding="UTF-8"?>
                                                #  <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
                                                #    <url>
                                                #      <loc>        URL                                               hints to what to visit. 
                                                #                                                                     Must be inside the same directory as Sitemap's parent's directory
                                                #      (optional)
                                                #      <lastmod>    YYYY[-MM[-DD[Thh:mm[:ss[.s]]TZ]]                  hints to when to visit
                                                #      <changefreq> always|hourly|daily|weekly|monthly|yearly|never   hints to when to visit
                                                #      <priority>   DOUBLE (from 0-1) (def: 0.5)                      when search engine picks between several possible pages
                                                #Sitemap index is a directory of sitemaps:
                                                #  <?xml version="1.0" encoding="UTF-8"?>
                                                #  <sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
                                                #    <sitemap>
                                                #      <loc> SITEMAP_URL
                                                #      (optional)
                                                #      <lastmod> ...

X-Robot-Tags: [useragent: ]"..." [S]            #Search engine hints for indexing:
<meta name="robots" content="WORD,...">/        #  - [no]index: index current page
                                                #  - [no]follow: 
                                                #     - index linked pages
															                  #     - nofollow sometimes used for user-generated content (e.g. comments) to avoid link spam
                                                #     - can also use Link; rel="follow" [S] or <any rel="nofollow">
                                                #  - noimageindex: index current page for image search (Google)
                                                #  - noodp: do not used auto-generated description if missing <meta name="description">
                                                #  - noydir: similar (Yahoo)
                                                #  - nosnippet: do not show description (Google)
                                                #  - noarchive: do not cache (Google, Yahoo)
                                                #  - nocache: do not cache (Bing)
<meta name="googlebot|slurp" content="STR">/    #Like "robots" but only for Google|Slurp


																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:          DESCRIPTION          :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


FOCUS ==>                                       #Should focus on specific topic

<title>                                         #
<meta name="description" content="STR">/        #Description, used by search engines and browsers bookmarks.
                                                #140 chars max.
                                                #Should be different for each page.
<meta name="keywords" content="STR...">/        #Search engine keywords
                                                #Do not put too many (cheating)

<h*>
<section>                                       #And related tags are used to get information structure

<iframe>                                        #To avoid


																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:        GOOD CONTENT           :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


BACKLINKS ==>                                   #Links point to this site
                                                #Avoid link farms (cheating)

TIME TO LONG CLICK ==>                          #  - how long before user come back to search engine to trigger same query ("pogosticking")
                                                #  - different from bounce rate, since some bounces do not trigger same query
                                                #  - slow performance can make people give up, i.e. increasing time to long click

																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:        TRANSFORMATIONS        :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


<meta name="google" content="WORD,...">/        #Google-specific:
                                                #  - notranslate: no Google translate


																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:         ACCESSIBILITY         :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


ACCESSIBILITY ==>                               #Crawlers are simple, i.e. page should be optimized for them:
                                                #  - should work with JavaScript, Java and Flash disabled
                                                #  - use text more than images and Flash
                                                #  - RESTful URLs


																						 /=+===============================+=\ 
																						/  :                               :  \  
							 														  )==:           SECURITY            :==(   
																						\  :_______________________________:  /    
																						 \=+===============================+=/


HTTPS ==>                                       #Should be used
