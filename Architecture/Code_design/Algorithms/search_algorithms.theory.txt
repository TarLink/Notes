
                     
   SEARCH_ALGORITHMS  
                     



SEARCH KEY ==>                    #Arbitrary starting vertex of search

BRUTE FORCE ==>                   #Trying all combinations|permutations
                                  #Also called "exhaustion".
                                  #Time complexity:
                                  #  - average|worst: O(mⁿ)
                                  #  - best: O(1)
                                  #Space complexity: O(1)
                                  #Can sort input:
                                  #  - so than can stop when > the searched value
                                  #  - to put more likely items first

LINEAR|SEQUENTIAL SEARCH ==>      #Brute force when trying to find an item in an array
                                  #Time complexity: O(n)

PRUNING ==>                       #During a search algorithm, skipping a node's descendants when they
                                  #can be guessed (from the parent's value) to be invalid.
                                  #Unless pruning can be done, search algorithms like BFS/DFS are conceptually a linear search.

BREADTH-FIRST SEARCH (BFS) ==>    #Search one level at a time, i.e.:
                                  #  - start at search key
                                  #  - visit each vertex with distance 1, then 2, etc.
                                  #Time complexity: O(order + size)
                                  #Space complexity: O(order)
                                  #Good when:
                                  #  - depth is big
                                  #  - searched value's height is probably high
                                  #Bad when:
                                  #  - space complexity is important
                                  #  - branching factor is big

DEPTH-FIRST SEARCH (DFS) ==>      #Search one path at a time (until cycle or dead-end), i.e.:
                                  #  - start at search key
                                  #  - visit vertex
                                  #  - if:
                                  #     - it has a leftmost non-visited child, repeat with that child
                                  #     - it is not the search key, repeat with parent ("backtrack")
                                  #     - it is the search key, stop
                                  #Also called "backtracking" when applying to more general algorithms
                                  #"Backjumping":
                                  #  - when it can known that a node and its descendants will be invalid because
                                  #    a siblings|cousin is invalid
                                  #Time complexity: O(order + size)
                                  #Space complexity: O(order)
                                  #Good when:
                                  #  - branching factor is big
                                  #  - searched value's height is probably low
                                  #Bad when:
                                  #  - depth is big

DEPTH-LIMITED SEARCH (DLS) ==>    #DFS where we stop when reaching a given depth.
                                  #Compensate some DFS problems but is an incomplete algorithm

ITERATIVE DEEPENING DFS (IDDFS)   #Running DLS iteratively with increasing depth.
 ==>                              #Also called "Iterative deepening search" (IDS)
                                  #Each iteration repeats DLS on nodes already visited:
                                  #  - cons: efficiency
                                  #  - pro: does not need to store nodes to know if already visited
                                  #I.e. has pros of BFS but without space complexity problem.

SEARCH TREE ==>                   #Ordered arborescence where left children < parent < right children.
                                  #Optimized for search algorithms
                                  #Most efficient when tree is balanced
                                  #Values can be stored either on each node or only on leaves

RANDOM SEARCH TREE ==>            #When shuffling nodes before inserting many of them in a search tree.
                                  #Reason: when inserting many sorted nodes (without balancing), this
                                  #will create a graph list as a subtree, increasing depth linearly.
                                  #Can also do a random pick among all possible trees after insertion of each
                                  #permutation of the nodes.
                                  #For a binary search tree, in average, depth will be:
                                  #  - mean: 2*log(n)+1
                                  #  - max: 4.3*log(n)

BINARY SEARCH TREE ==>            #Search tree where outdegree = 2
                                  #Optimized for search ("binary search"):
                                  #  - in-order search starting from root
                                  #Time complexity:
                                  #  - search:
                                  #     - average|worst:
                                  #        - if balanced: O(log n)
                                  #        - without proper balancing:
                                  #           - height will average sqrt(order), and complexity O(sqrt n)
                                  #           - can even be O(n) if search tree degenerated into a line graph
                                  #  - insert|delete:
                                  #     - like search
                                  #     - first search of it, then perform constant-time insert|delete

B-TREE ==>                        #Search tree where:
                                  #  - outdegree <= NUM2 ("order") and >= NUM
                                  #     - often NUM = NUM2/2+1/2
                                  #  - node's value is an array or numbers:
                                  #     - acting as separators between each two children
                                  #Similar to binary search tree:
                                  #  - which can be considered a b-tree of order 2
                                  #  - higher order:
                                  #     - better when nodes are read|write sequentially
                                  #        - i.e. when siblings nodes are usually read|write together
                                  #        - e.g. a file's blocks
                                  #     - instead of O(log₂ n), performs in O(m*logₘ n) to find node
                                  #       (which is worst), but then iterating|inserting|deleting siblings is faster
                                  #     - worst time complexity: some space is empty
                                  #     - less frequent balancing needed

B+ TREE ==>                       #B-tree where:
                                  #  - values are stored only on leaves
                                  #  - each leaf contains a pointer to next leaf (i.e. linked list)
                                  #I.e. like B-tree but with better sequential access accross several leaves.

HEAP ==>                          #Tree satisfying the "heap property":
                                  #  - "max heap": parent node's key >= child's key
                                  #  - "min heap": parent node's key <= child's key
                                  #Useful to search min|max value, e.g. to implement a priority queue.
                                  #As opposed to search tree, is always balanced.
                                  #Operations:
                                  #  - peek_max|min(): O(1)
                                  #  - pull_max|min(): O(log n)
                                  #  - insert(NODE): O(log n)
                                  #  - delete(): arbitrary node
                                  #  - set_key(NODE, KEY): O(log n)
                                  #  - merge(HEAP, HEAP2)->HEAP3: O(n)
                                  #  - size()->NUM
                                  #Complexity depends on implementation (those are the most common).





B-TREE ==>                        #
                                  #  - <= U children, >= L children
                                  #     - L = ⌈U/2⌉
                                  #     - U = 2L or 2L-1
                                  #  - no lower limit of children for root
                                  #  - U can be picked to try to make nodes the same size as an I/O block
                                  #  - if U is very high, can:
                                  #     - implement keys as a search tree themselves instead of a simple array
                                  #     - use delta encoding compression on keys (better space, worst time)
                                  #Self-balancing:
                                  #  - if node full|empty, can:
                                  #     - transfer ("rotation") or "merge|split" between siblings
                                  #        - must change parent keys as well
                                  #     - merge|split child to|from parent
                                  #  - must be done recursively from node to root
                                  #  - can be done either:
                                  #     - between operations
                                  #     - during operation, as nodes are being visited


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          ALGORITHMS           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


PARALLELISM ==>                   #Capacity of an algorithm to be performed in parallel.
                                  #"Parallel random-access machine" (PRAM):
                                  #  - abstraction of CPUs accessing shared memory
                                  #  - capacities:
                                  #     - read can be allowed concurrently or be exclusive
                                  #     - write can be allowed concurrently or be exclusive
                                  #        - if concurrent, write can be:
                                  #           - "common": conflicts are invalid
                                  #           - "arbitrary": random CPU gets priority
                                  #           - "priority": CPU have a specific priority number
                                  #     - called "Exclusive|concurrent read exclusive|concurrent write"
                                  #       ("EREW"/"CREW"/"ERCW"/"CRCW")
                                  #         - "CRCW" also called "concurrent RAM"
                                  #  - simplification:
                                  #     - infinite CPUs and RAM
                                  #  - time complexity:
                                  #     - difference between:
                                  #       - operations that can be run in parallel
                                  #       - operations that cannot
                                  #          - the longest is the "critical path"
                                  #     - p: number of processors
                                  #     - T₁:
                                  #       - "work": amount of time of 1 CPU
                                  #     - Tₚ:
                                  #       - amount of time of p CPUs
                                  #       - "cost" is p*Tₚ
                                  #          - "work law": it is >= T₁ because of cost of critical path
                                  #          - "span law": it is <= T∞
                                  #     - T∞:
                                  #       - amount of time of an infinite number CPUs
                                  #       - i.e. reduced to critical path
                                  #     - Sₚ:
                                  #       - "speedup":
                                  #          - T₁/Tₚ
                                  #          - i.e. number of CPUs actually used, time-wise
                                  #          - expressed in O() notation
                                  #          - "linear"/"scalable": O(n)
                                  #          - "perfect linear": when same as p
                                  #          - can be divided between speedup in latency and in throughput
                                  #       - "efficiency":
                                  #          - speedup/p
                                  #          - i.e. like speedup but as percentage
                                  #       - "parallelism":
                                  #          - T₁/T∞
                                  #          - i.e. inverse of percentage critical path
                                  #       - "slackness":
                                  #          - parallelism/p
                                  #          - i.e. like parallelism but as percentage
                                  #In practice:
                                  #  - only specific hardware allow concurrent memory read|write, e.g. SRAM
                                  #  - must do at very low-level, e.g. using FPGA
